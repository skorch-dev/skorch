{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e9d7c4",
   "metadata": {},
   "source": [
    "# Using LLMs as text classifiers with an sklearn interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a5964",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- filter warnings\n",
    "- google colab installs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e300c",
   "metadata": {},
   "source": [
    "<table align=\"left\"><td>\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/llm-classifier-demo.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
    "</td><td>\n",
    "<a target=\"_blank\" href=\"https://github.com/skorch-dev/skorch/blob/master/notebooks/llm-classifier-demo.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efca3d7",
   "metadata": {},
   "source": [
    "The first part of the notebook requires Hugging Face `transformers` and `datasets` as additional dependencies. If you have not already installed it, you can do so like this:\n",
    "\n",
    "`python -m pip install transformers datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b71dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Installation on Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.run(['python', '-m', 'pip', 'install', 'skorch', 'transformers', 'datasets'])\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a39e0",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb9b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77a93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_error()\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396ef339",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6fa7e",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef93cf4",
   "metadata": {},
   "source": [
    "Load sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7cbed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be57b9994e4544838f19e0a5a2bf8641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb = datasets.load_dataset('imdb').shuffle(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a4d2e9",
   "metadata": {},
   "source": [
    "Limit to 100 samples. Using zero/few shot learning mostly makes sense when there are very few labeled samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1abbf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imdb['train'][:100]['text']\n",
    "y = imdb['train'][:100]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6083b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(['negative', 'positive'])[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59274ec5",
   "metadata": {},
   "source": [
    "## zero shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "788acccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.llm import ZeroShotClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58978978",
   "metadata": {},
   "source": [
    "### \"train\" zero shot classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29781f",
   "metadata": {},
   "source": [
    "For this notebook, we use a small LLM, `flan-t5-small`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638b8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ZeroShotClassifier(\n",
    "    'google/flan-t5-small', generate_kwargs={'max_length': 512}, device=device, use_caching=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12888d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.93 s, sys: 590 ms, total: 3.52 s\n",
      "Wall time: 3.27 s\n"
     ]
    }
   ],
   "source": [
    "%time clf.fit(X=None, y=['positive', 'negative']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1635eddc",
   "metadata": {},
   "source": [
    "In general, fitting is fast because, basically, nothing happens. If the LLM is not cached locally, it will, however, be downloaded from Hugging Face, which may take some time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba5234",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a17bf2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.4 s, sys: 1.37 s, total: 29.7 s\n",
      "Wall time: 7.85 s\n"
     ]
    }
   ],
   "source": [
    "%time y_proba = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fc5b571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3767035707377107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b61915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_proba.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0d4b490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6807dc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype='<U8')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([\"A masterpiece, instant classic, 5 stars out of 5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e4528",
   "metadata": {},
   "source": [
    "### grid search the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d143b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt0 = \"\"\"You are a text classification assistant.\n",
    "\n",
    "The text to classify:\n",
    "\n",
    "```\n",
    "{text}\n",
    "```\n",
    "\n",
    "Choose the label among the following possibilities with the highest probability.\n",
    "Only return the label, nothing more:\n",
    "\n",
    "{labels}\n",
    "\n",
    "Your response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfcf1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"\"\"Your task is to classify text.\n",
    "\n",
    "Choose the label among the following possibilities with the highest probability.\n",
    "Only return the label, nothing more:\n",
    "\n",
    "{labels}\n",
    "\n",
    "The text to classify:\n",
    "\n",
    "```\n",
    "{text}\n",
    "```\n",
    "\n",
    "Your response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b403856",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'prompt': [prompt0, prompt1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "513248bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(clf, param_grid=params, cv=2, scoring=['accuracy', 'neg_log_loss'], refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84fdf44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 53s, sys: 5.32 s, total: 1min 58s\n",
      "Wall time: 33.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=ZeroShotClassifier(device=&#x27;cuda:0&#x27;, generate_kwargs={&#x27;max_length&#x27;: 512}, model_name=&#x27;google/flan-t5-small&#x27;, use_caching=False),\n",
       "             param_grid={&#x27;prompt&#x27;: [&#x27;You are a text classification assistant.\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;The text to classify:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;{text}\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Choose the label among the following &#x27;\n",
       "                                    &#x27;possibilities with the highest &#x27;\n",
       "                                    &#x27;probability.\\n&#x27;\n",
       "                                    &#x27;O...the label, nothing more:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;{labels}\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Your response:\\n&#x27;,\n",
       "                                    &#x27;Your task is to classify text.\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Choose the label among the following &#x27;\n",
       "                                    &#x27;possibilities with the highest &#x27;\n",
       "                                    &#x27;probability.\\n&#x27;\n",
       "                                    &#x27;Only return the label, nothing more:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;{labels}\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;The text to classify:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;{text}\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Your response:\\n&#x27;]},\n",
       "             refit=False, scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=ZeroShotClassifier(device=&#x27;cuda:0&#x27;, generate_kwargs={&#x27;max_length&#x27;: 512}, model_name=&#x27;google/flan-t5-small&#x27;, use_caching=False),\n",
       "             param_grid={&#x27;prompt&#x27;: [&#x27;You are a text classification assistant.\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;The text to classify:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;{text}\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Choose the label among the following &#x27;\n",
       "                                    &#x27;possibilities with the highest &#x27;\n",
       "                                    &#x27;probability.\\n&#x27;\n",
       "                                    &#x27;O...the label, nothing more:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;{labels}\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Your response:\\n&#x27;,\n",
       "                                    &#x27;Your task is to classify text.\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Choose the label among the following &#x27;\n",
       "                                    &#x27;possibilities with the highest &#x27;\n",
       "                                    &#x27;probability.\\n&#x27;\n",
       "                                    &#x27;Only return the label, nothing more:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;{labels}\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;The text to classify:\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;{text}\\n&#x27;\n",
       "                                    &#x27;```\\n&#x27;\n",
       "                                    &#x27;\\n&#x27;\n",
       "                                    &#x27;Your response:\\n&#x27;]},\n",
       "             refit=False, scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ZeroShotClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotClassifier(device=&#x27;cuda:0&#x27;, generate_kwargs={&#x27;max_length&#x27;: 512}, model_name=&#x27;google/flan-t5-small&#x27;, use_caching=False)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ZeroShotClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotClassifier(device=&#x27;cuda:0&#x27;, generate_kwargs={&#x27;max_length&#x27;: 512}, model_name=&#x27;google/flan-t5-small&#x27;, use_caching=False)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=ZeroShotClassifier(device='cuda:0', generate_kwargs={'max_length': 512}, model_name='google/flan-t5-small', use_caching=False),\n",
       "             param_grid={'prompt': ['You are a text classification assistant.\\n'\n",
       "                                    '\\n'\n",
       "                                    'The text to classify:\\n'\n",
       "                                    '\\n'\n",
       "                                    '```\\n'\n",
       "                                    '{text}\\n'\n",
       "                                    '```\\n'\n",
       "                                    '\\n'\n",
       "                                    'Choose the label among the following '\n",
       "                                    'possibilities with the highest '\n",
       "                                    'probability.\\n'\n",
       "                                    'O...the label, nothing more:\\n'\n",
       "                                    '\\n'\n",
       "                                    '{labels}\\n'\n",
       "                                    '\\n'\n",
       "                                    'Your response:\\n',\n",
       "                                    'Your task is to classify text.\\n'\n",
       "                                    '\\n'\n",
       "                                    'Choose the label among the following '\n",
       "                                    'possibilities with the highest '\n",
       "                                    'probability.\\n'\n",
       "                                    'Only return the label, nothing more:\\n'\n",
       "                                    '\\n'\n",
       "                                    '{labels}\\n'\n",
       "                                    '\\n'\n",
       "                                    'The text to classify:\\n'\n",
       "                                    '\\n'\n",
       "                                    '```\\n'\n",
       "                                    '{text}\\n'\n",
       "                                    '```\\n'\n",
       "                                    '\\n'\n",
       "                                    'Your response:\\n']},\n",
       "             refit=False, scoring=['accuracy', 'neg_log_loss'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time search.fit(X, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f15f5",
   "metadata": {},
   "source": [
    "grid search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66820321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>param_prompt</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.87</td>\n",
       "      <td>-0.296063</td>\n",
       "      <td>You are a text classification assistant.\\n\\nTh...</td>\n",
       "      <td>6.847503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>-0.246425</td>\n",
       "      <td>Your task is to classify text.\\n\\nChoose the l...</td>\n",
       "      <td>6.929659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_accuracy  mean_test_neg_log_loss  \\\n",
       "0                0.87               -0.296063   \n",
       "1                0.93               -0.246425   \n",
       "\n",
       "                                        param_prompt  mean_score_time  \n",
       "0  You are a text classification assistant.\\n\\nTh...         6.847503  \n",
       "1  Your task is to classify text.\\n\\nChoose the l...         6.929659  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_)[['mean_test_accuracy', 'mean_test_neg_log_loss', 'param_prompt', 'mean_score_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81bdc1a",
   "metadata": {},
   "source": [
    "**Conclusion**: `prompt1` is performing better. Mean test accuracy of 93% and log loss of 0.25 are pretty good, given that we use zero shot and don't perform any fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370cf500",
   "metadata": {},
   "source": [
    "## few shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea5da394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.llm import FewShotClassifier\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd48ed8",
   "metadata": {},
   "source": [
    "### train few shot classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d1cd17",
   "metadata": {},
   "source": [
    "Instead of passing the model name to initialize the classifier, as in `clf = FewShotClassifier('google/flan-t5-small')`, it is also possible to pass the model and tokenizer explicitly. This is a good option if you need more control over them. In our case, it amounts to the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afdb149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-small').to('cuda:0')\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9de3297",
   "metadata": {},
   "source": [
    "Use `max_samples` samples from the training data for few shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a968c6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = FewShotClassifier(\n",
    "    model=model, tokenizer=tokenizer, max_samples=5, generate_kwargs={'max_length': 512}, use_caching=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1c9af63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 815 µs, sys: 42 µs, total: 857 µs\n",
      "Wall time: 386 µs\n"
     ]
    }
   ],
   "source": [
    "%time clf.fit(X[:5], labels[:5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb8839",
   "metadata": {},
   "source": [
    "Show how the prompt looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2693aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a text classification assistant.\n",
      "\n",
      "Choose the label among the following possibilities with the highest probability.\n",
      "Only return the label, nothing more:\n",
      "\n",
      "['negative' 'positive']\n",
      "\n",
      "Here are a few examples:\n",
      "\n",
      "```\n",
      "I watch lots of scary movies (or at least they try to be) and this has to be the worst if not 2nd worst movie I have ever had to make myself try to sit through. I never knew the depths of Masacism until I rented this piece of moldy cheese covered in a used latex contraceptive. I am a fan of Julian Sans, but this is worse than I would hope for him.<br /><br />On the other hand the story was promising and I was intrigued...for the first minute and a half while the credits rolled and I had yet to see what pain looked like first hand. Perhaps there are some viewers out there that enjoyed this and can point me in the right direction, but then again I know of those viewers who understand if not commemorate me, especially when we had to turn the video off, and that simply is NOT done with our watching (we had to make one exception obviously). <br /><br />If it were up for a remake, I'd give it a chance so long as they had at most 1% of the original incorporated into it. That's all.\n",
      "```\n",
      "\n",
      "Your response:\n",
      "negative\n",
      "\n",
      "```\n",
      "We always watch American movies with their particular accents from each region (south, west, etc). We have the same here. All foreign people must to watch this movie and need to have a open mind to accept another culture, besides American and European almost dominate the cinematographic industry.<br /><br />This movie tell us about a parallel world which it isn't figured even for those who live in a big city like São Paulo. All actors are improvising and they are very realistic. The camera give us an idea of their confuse world, the loneliness of each character and invite us to share their world.<br /><br />It's a real great movie and worst a rent even have it at home.\n",
      "```\n",
      "\n",
      "Your response:\n",
      "positive\n",
      "\n",
      "```\n",
      "I liked how this started out, featuring some decent special-effects especially for a film 50 years old. There was some pretty impressive scenery. However, the film bogs down fairly early on with some very dumb dialog as the males all try to flirt with Anne Francis \"Altaira Morbius.\")<br /><br />Viewing this in the '90s after a long absence, it was fun to see Francis again, an actress who has done mostly television shows since this film was released....and is still acting. It also was interesting to see a young-looking Leslie Nielsen (\"Dr. John J. Adams\"), who I wouldn't have recognized had it not been for this voice <br /><br />I watched half of this movie before the boredom came almost overwhelming and I had a strong desire to go to sleep. I appreciated them re-doing this VHS tape in stereo. but it was a weak effort. This is one those overrated film where \"elites\" think is so \"heavy\" and \"thought-provoking.\" That's nonsense. It only appeared \"intelligent\" because the rest of the '50s sci-fi films were so stupid!!<br /><br />Some if the early scenes would have looked great on wideescreen, which I didn't have at the time of this writing. Perhaps another look - this time on the 2.35:1 widescreen transfer would make me change this review.\n",
      "```\n",
      "\n",
      "Your response:\n",
      "negative\n",
      "\n",
      "```\n",
      "I liked how this started out, featuring some decent special-effects especially for a film 50 years old. There was some pretty impressive scenery. However, the film bogs down fairly early on with some very dumb dialog as the males all try to flirt with Anne Francis \"Altaira Morbius.\")<br /><br />Viewing this in the '90s after a long absence, it was fun to see Francis again, an actress who has done mostly television shows since this film was released....and is still acting. It also was interesting to see a young-looking Leslie Nielsen (\"Dr. John J. Adams\"), who I wouldn't have recognized had it not been for this voice <br /><br />I watched half of this movie before the boredom came almost overwhelming and I had a strong desire to go to sleep. I appreciated them re-doing this VHS tape in stereo. but it was a weak effort. This is one those overrated film where \"elites\" think is so \"heavy\" and \"thought-provoking.\" That's nonsense. It only appeared \"intelligent\" because the rest of the '50s sci-fi films were so stupid!!<br /><br />Some if the early scenes would have looked great on wideescreen, which I didn't have at the time of this writing. Perhaps another look - this time on the 2.35:1 widescreen transfer would make me change this review.\n",
      "```\n",
      "\n",
      "Your response:\n",
      "negative\n",
      "\n",
      "```\n",
      "i went to see this movie with a bunch of friends one night. I didn't really hear much about it. So I wasn't expecting anything. But after I saw it, I really liked it. Nicolas Cage and the rest of the cast were very good. But I do have to say Giovanni Ribisi's acting performace did need a little perking up. But such a small flaw, it could be overrided. <br /><br />Gone In 60 Seconds is about a retired car thief who must boost 60 rare and exotic cars in one night to save his brother's life. The movie is in no way predictable. So the ending should be a suprise. Think it's just another, fast car driving movie? Well you are partially right. There is much more to it. Everyone should take a look at this movie.\n",
      "```\n",
      "\n",
      "Your response:\n",
      "positive\n",
      "\n",
      "\n",
      "The text to classify:\n",
      "\n",
      "```\n",
      "\"CASOMAI\" was the last movie I've seen before getting married, just last year. <br /><br />It was also the first movie I've searched for, after I was married, because we promised to offer a copy to our priest.<br /><br />Sometimes, reality is not that apart from fiction. To all those who wrote that priests like \"Don Camillo\" don't exist in real life, I would recommend them to visit my Priest Pe. Nuno Westwood, in Estoril, Portugal :-)<br /><br />To all others, I would only recommend them to see this movie, before and after the \"I do!\" day :-)<br /><br />Rodrigo Ribeiro Portugal\n",
      "```\n",
      "\n",
      "Your response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf.get_prompt(X[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b96c37",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef634677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 2.77 s, total: 1min 5s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%time y_proba = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "406490a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23828560002899238"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b82e0318",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_proba.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1327b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6416221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype='<U8')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([\"Even if paid $1000, I would not watch this movie again\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2144f69",
   "metadata": {},
   "source": [
    "### grid search best number of few shot samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef2a44",
   "metadata": {},
   "source": [
    "Note that grid search will split `X` and `y` for each run. Since the few shot samples are taken from X and y, those will thus be different for each split, which could have a big influence on the performance of the model. If you always want to have the same few shot samples in each split, you should craft your own prompt with those examples and then use it with `ZeroShotClassifier`. Just ensure that those prompts are not part of the validation/test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b301636",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_samples': [3, 5, 7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3eaa06e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(clf, param_grid=params, cv=2, scoring=['accuracy', 'neg_log_loss'], refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39d42f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 17s, sys: 27 s, total: 10min 44s\n",
      "Wall time: 2min 53s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=FewShotClassifier(generate_kwargs={&#x27;max_length&#x27;: 512}, model=T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=Fa...\n",
       "), tokenizer=T5TokenizerFast(name_or_path=&#x27;google/flan-t5-small&#x27;, vocab_size=32100, model_max_length=512, is_fast=True, padding_side=&#x27;right&#x27;, truncation_side=&#x27;right&#x27;, special_tokens={&#x27;eos_token&#x27;: &#x27;&lt;/s&gt;&#x27;, &#x27;unk_token&#x27;: &#x27;&lt;unk&gt;&#x27;, &#x27;pad_token&#x27;: &#x27;&lt;pad&gt;&#x27;, &#x27;additional_special_tokens&#x27;: [&#x27;&lt;extra_id_0&gt;&#x27;, &#x27;&lt;extra_id_1&gt;&#x27;, &#x27;&lt;extra_id_2&gt;&#x27;, &#x27;&lt;extra_id_3&gt;&#x27;, &#x27;&lt;extra_id_4&gt;&#x27;, &#x27;&lt;extra_id_5&gt;&#x27;, &#x27;&lt;extra_id_6&gt;&#x27;, &#x27;&lt;extra_id_7&gt;&#x27;, &#x27;&lt;extra_id_8&gt;&#x27;, &#x27;&lt;extra_id_9&gt;&#x27;, &#x27;&lt;extra_id_10&gt;&#x27;, &#x27;&lt;extra_id_11&gt;&#x27;, &#x27;&lt;extra_id_12&gt;&#x27;, &#x27;&lt;extra_id_13&gt;&#x27;, &#x27;&lt;extra_id_14&gt;&#x27;, &#x27;&lt;extra_id_15&gt;&#x27;, &#x27;&lt;extra_id_16&gt;&#x27;, &#x27;&lt;extra_id_17&gt;&#x27;, &#x27;&lt;extra_id_18&gt;&#x27;, &#x27;&lt;extra_id_19&gt;&#x27;, &#x27;&lt;extra_id_20&gt;&#x27;, &#x27;&lt;extra_id_21&gt;&#x27;, &#x27;&lt;extra_id_22&gt;&#x27;, &#x27;&lt;extra_id_23&gt;&#x27;, &#x27;&lt;extra_id_24&gt;&#x27;, &#x27;&lt;extra_id_25&gt;&#x27;, &#x27;&lt;extra_id_26&gt;&#x27;, &#x27;&lt;extra_id_27&gt;&#x27;, &#x27;&lt;extra_id_28&gt;&#x27;, &#x27;&lt;extra_id_29&gt;&#x27;, &#x27;&lt;extra_id_30&gt;&#x27;, &#x27;&lt;extra_id_31&gt;&#x27;, &#x27;&lt;extra_id_32&gt;&#x27;, &#x27;&lt;extra_id_33&gt;&#x27;, &#x27;&lt;extra_id_34&gt;&#x27;, &#x27;&lt;extra_id_35&gt;&#x27;, &#x27;&lt;extra_id_36&gt;&#x27;, &#x27;&lt;extra_id_37&gt;&#x27;, &#x27;&lt;extra_id_38&gt;&#x27;, &#x27;&lt;extra_id_39&gt;&#x27;, &#x27;&lt;extra_id_40&gt;&#x27;, &#x27;&lt;extra_id_41&gt;&#x27;, &#x27;&lt;extra_id_42&gt;&#x27;, &#x27;&lt;extra_id_43&gt;&#x27;, &#x27;&lt;extra_id_44&gt;&#x27;, &#x27;&lt;extra_id_45&gt;&#x27;, &#x27;&lt;extra_id_46&gt;&#x27;, &#x27;&lt;extra_id_47&gt;&#x27;, &#x27;&lt;extra_id_48&gt;&#x27;, &#x27;&lt;extra_id_49&gt;&#x27;, &#x27;&lt;extra_id_50&gt;&#x27;, &#x27;&lt;extra_id_51&gt;&#x27;, &#x27;&lt;extra_id_52&gt;&#x27;, &#x27;&lt;extra_id_53&gt;&#x27;, &#x27;&lt;extra_id_54&gt;&#x27;, &#x27;&lt;extra_id_55&gt;&#x27;, &#x27;&lt;extra_id_56&gt;&#x27;, &#x27;&lt;extra_id_57&gt;&#x27;, &#x27;&lt;extra_id_58&gt;&#x27;, &#x27;&lt;extra_id_59&gt;&#x27;, &#x27;&lt;extra_id_60&gt;&#x27;, &#x27;&lt;extra_id_61&gt;&#x27;, &#x27;&lt;extra_id_62&gt;&#x27;, &#x27;&lt;extra_id_63&gt;&#x27;, &#x27;&lt;extra_id_64&gt;&#x27;, &#x27;&lt;extra_id_65&gt;&#x27;, &#x27;&lt;extra_id_66&gt;&#x27;, &#x27;&lt;extra_id_67&gt;&#x27;, &#x27;&lt;extra_id_68&gt;&#x27;, &#x27;&lt;extra_id_69&gt;&#x27;, &#x27;&lt;extra_id_70&gt;&#x27;, &#x27;&lt;extra_id_71&gt;&#x27;, &#x27;&lt;extra_id_72&gt;&#x27;, &#x27;&lt;extra_id_73&gt;&#x27;, &#x27;&lt;extra_id_74&gt;&#x27;, &#x27;&lt;extra_id_75&gt;&#x27;, &#x27;&lt;extra_id_76&gt;&#x27;, &#x27;&lt;extra_id_77&gt;&#x27;, &#x27;&lt;extra_id_78&gt;&#x27;, &#x27;&lt;extra_id_79&gt;&#x27;, &#x27;&lt;extra_id_80&gt;&#x27;, &#x27;&lt;extra_id_81&gt;&#x27;, &#x27;&lt;extra_id_82&gt;&#x27;, &#x27;&lt;extra_id_83&gt;&#x27;, &#x27;&lt;extra_id_84&gt;&#x27;, &#x27;&lt;extra_id_85&gt;&#x27;, &#x27;&lt;extra_id_86&gt;&#x27;, &#x27;&lt;extra_id_87&gt;&#x27;, &#x27;&lt;extra_id_88&gt;&#x27;, &#x27;&lt;extra_id_89&gt;&#x27;, &#x27;&lt;extra_id_90&gt;&#x27;, &#x27;&lt;extra_id_91&gt;&#x27;, &#x27;&lt;extra_id_92&gt;&#x27;, &#x27;&lt;extra_id_93&gt;&#x27;, &#x27;&lt;extra_id_94&gt;&#x27;, &#x27;&lt;extra_id_95&gt;&#x27;, &#x27;&lt;extra_id_96&gt;&#x27;, &#x27;&lt;extra_id_97&gt;&#x27;, &#x27;&lt;extra_id_98&gt;&#x27;, &#x27;&lt;extra_id_99&gt;&#x27;]}, clean_up_tokenization_spaces=True), use_caching=False),\n",
       "             param_grid={&#x27;max_samples&#x27;: [3, 5, 7]}, refit=False,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=FewShotClassifier(generate_kwargs={&#x27;max_length&#x27;: 512}, model=T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=Fa...\n",
       "), tokenizer=T5TokenizerFast(name_or_path=&#x27;google/flan-t5-small&#x27;, vocab_size=32100, model_max_length=512, is_fast=True, padding_side=&#x27;right&#x27;, truncation_side=&#x27;right&#x27;, special_tokens={&#x27;eos_token&#x27;: &#x27;&lt;/s&gt;&#x27;, &#x27;unk_token&#x27;: &#x27;&lt;unk&gt;&#x27;, &#x27;pad_token&#x27;: &#x27;&lt;pad&gt;&#x27;, &#x27;additional_special_tokens&#x27;: [&#x27;&lt;extra_id_0&gt;&#x27;, &#x27;&lt;extra_id_1&gt;&#x27;, &#x27;&lt;extra_id_2&gt;&#x27;, &#x27;&lt;extra_id_3&gt;&#x27;, &#x27;&lt;extra_id_4&gt;&#x27;, &#x27;&lt;extra_id_5&gt;&#x27;, &#x27;&lt;extra_id_6&gt;&#x27;, &#x27;&lt;extra_id_7&gt;&#x27;, &#x27;&lt;extra_id_8&gt;&#x27;, &#x27;&lt;extra_id_9&gt;&#x27;, &#x27;&lt;extra_id_10&gt;&#x27;, &#x27;&lt;extra_id_11&gt;&#x27;, &#x27;&lt;extra_id_12&gt;&#x27;, &#x27;&lt;extra_id_13&gt;&#x27;, &#x27;&lt;extra_id_14&gt;&#x27;, &#x27;&lt;extra_id_15&gt;&#x27;, &#x27;&lt;extra_id_16&gt;&#x27;, &#x27;&lt;extra_id_17&gt;&#x27;, &#x27;&lt;extra_id_18&gt;&#x27;, &#x27;&lt;extra_id_19&gt;&#x27;, &#x27;&lt;extra_id_20&gt;&#x27;, &#x27;&lt;extra_id_21&gt;&#x27;, &#x27;&lt;extra_id_22&gt;&#x27;, &#x27;&lt;extra_id_23&gt;&#x27;, &#x27;&lt;extra_id_24&gt;&#x27;, &#x27;&lt;extra_id_25&gt;&#x27;, &#x27;&lt;extra_id_26&gt;&#x27;, &#x27;&lt;extra_id_27&gt;&#x27;, &#x27;&lt;extra_id_28&gt;&#x27;, &#x27;&lt;extra_id_29&gt;&#x27;, &#x27;&lt;extra_id_30&gt;&#x27;, &#x27;&lt;extra_id_31&gt;&#x27;, &#x27;&lt;extra_id_32&gt;&#x27;, &#x27;&lt;extra_id_33&gt;&#x27;, &#x27;&lt;extra_id_34&gt;&#x27;, &#x27;&lt;extra_id_35&gt;&#x27;, &#x27;&lt;extra_id_36&gt;&#x27;, &#x27;&lt;extra_id_37&gt;&#x27;, &#x27;&lt;extra_id_38&gt;&#x27;, &#x27;&lt;extra_id_39&gt;&#x27;, &#x27;&lt;extra_id_40&gt;&#x27;, &#x27;&lt;extra_id_41&gt;&#x27;, &#x27;&lt;extra_id_42&gt;&#x27;, &#x27;&lt;extra_id_43&gt;&#x27;, &#x27;&lt;extra_id_44&gt;&#x27;, &#x27;&lt;extra_id_45&gt;&#x27;, &#x27;&lt;extra_id_46&gt;&#x27;, &#x27;&lt;extra_id_47&gt;&#x27;, &#x27;&lt;extra_id_48&gt;&#x27;, &#x27;&lt;extra_id_49&gt;&#x27;, &#x27;&lt;extra_id_50&gt;&#x27;, &#x27;&lt;extra_id_51&gt;&#x27;, &#x27;&lt;extra_id_52&gt;&#x27;, &#x27;&lt;extra_id_53&gt;&#x27;, &#x27;&lt;extra_id_54&gt;&#x27;, &#x27;&lt;extra_id_55&gt;&#x27;, &#x27;&lt;extra_id_56&gt;&#x27;, &#x27;&lt;extra_id_57&gt;&#x27;, &#x27;&lt;extra_id_58&gt;&#x27;, &#x27;&lt;extra_id_59&gt;&#x27;, &#x27;&lt;extra_id_60&gt;&#x27;, &#x27;&lt;extra_id_61&gt;&#x27;, &#x27;&lt;extra_id_62&gt;&#x27;, &#x27;&lt;extra_id_63&gt;&#x27;, &#x27;&lt;extra_id_64&gt;&#x27;, &#x27;&lt;extra_id_65&gt;&#x27;, &#x27;&lt;extra_id_66&gt;&#x27;, &#x27;&lt;extra_id_67&gt;&#x27;, &#x27;&lt;extra_id_68&gt;&#x27;, &#x27;&lt;extra_id_69&gt;&#x27;, &#x27;&lt;extra_id_70&gt;&#x27;, &#x27;&lt;extra_id_71&gt;&#x27;, &#x27;&lt;extra_id_72&gt;&#x27;, &#x27;&lt;extra_id_73&gt;&#x27;, &#x27;&lt;extra_id_74&gt;&#x27;, &#x27;&lt;extra_id_75&gt;&#x27;, &#x27;&lt;extra_id_76&gt;&#x27;, &#x27;&lt;extra_id_77&gt;&#x27;, &#x27;&lt;extra_id_78&gt;&#x27;, &#x27;&lt;extra_id_79&gt;&#x27;, &#x27;&lt;extra_id_80&gt;&#x27;, &#x27;&lt;extra_id_81&gt;&#x27;, &#x27;&lt;extra_id_82&gt;&#x27;, &#x27;&lt;extra_id_83&gt;&#x27;, &#x27;&lt;extra_id_84&gt;&#x27;, &#x27;&lt;extra_id_85&gt;&#x27;, &#x27;&lt;extra_id_86&gt;&#x27;, &#x27;&lt;extra_id_87&gt;&#x27;, &#x27;&lt;extra_id_88&gt;&#x27;, &#x27;&lt;extra_id_89&gt;&#x27;, &#x27;&lt;extra_id_90&gt;&#x27;, &#x27;&lt;extra_id_91&gt;&#x27;, &#x27;&lt;extra_id_92&gt;&#x27;, &#x27;&lt;extra_id_93&gt;&#x27;, &#x27;&lt;extra_id_94&gt;&#x27;, &#x27;&lt;extra_id_95&gt;&#x27;, &#x27;&lt;extra_id_96&gt;&#x27;, &#x27;&lt;extra_id_97&gt;&#x27;, &#x27;&lt;extra_id_98&gt;&#x27;, &#x27;&lt;extra_id_99&gt;&#x27;]}, clean_up_tokenization_spaces=True), use_caching=False),\n",
       "             param_grid={&#x27;max_samples&#x27;: [3, 5, 7]}, refit=False,\n",
       "             scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: FewShotClassifier</label><div class=\"sk-toggleable__content\"><pre>FewShotClassifier(generate_kwargs={&#x27;max_length&#x27;: 512}, model=T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=5...\n",
       "), tokenizer=T5TokenizerFast(name_or_path=&#x27;google/flan-t5-small&#x27;, vocab_size=32100, model_max_length=512, is_fast=True, padding_side=&#x27;right&#x27;, truncation_side=&#x27;right&#x27;, special_tokens={&#x27;eos_token&#x27;: &#x27;&lt;/s&gt;&#x27;, &#x27;unk_token&#x27;: &#x27;&lt;unk&gt;&#x27;, &#x27;pad_token&#x27;: &#x27;&lt;pad&gt;&#x27;, &#x27;additional_special_tokens&#x27;: [&#x27;&lt;extra_id_0&gt;&#x27;, &#x27;&lt;extra_id_1&gt;&#x27;, &#x27;&lt;extra_id_2&gt;&#x27;, &#x27;&lt;extra_id_3&gt;&#x27;, &#x27;&lt;extra_id_4&gt;&#x27;, &#x27;&lt;extra_id_5&gt;&#x27;, &#x27;&lt;extra_id_6&gt;&#x27;, &#x27;&lt;extra_id_7&gt;&#x27;, &#x27;&lt;extra_id_8&gt;&#x27;, &#x27;&lt;extra_id_9&gt;&#x27;, &#x27;&lt;extra_id_10&gt;&#x27;, &#x27;&lt;extra_id_11&gt;&#x27;, &#x27;&lt;extra_id_12&gt;&#x27;, &#x27;&lt;extra_id_13&gt;&#x27;, &#x27;&lt;extra_id_14&gt;&#x27;, &#x27;&lt;extra_id_15&gt;&#x27;, &#x27;&lt;extra_id_16&gt;&#x27;, &#x27;&lt;extra_id_17&gt;&#x27;, &#x27;&lt;extra_id_18&gt;&#x27;, &#x27;&lt;extra_id_19&gt;&#x27;, &#x27;&lt;extra_id_20&gt;&#x27;, &#x27;&lt;extra_id_21&gt;&#x27;, &#x27;&lt;extra_id_22&gt;&#x27;, &#x27;&lt;extra_id_23&gt;&#x27;, &#x27;&lt;extra_id_24&gt;&#x27;, &#x27;&lt;extra_id_25&gt;&#x27;, &#x27;&lt;extra_id_26&gt;&#x27;, &#x27;&lt;extra_id_27&gt;&#x27;, &#x27;&lt;extra_id_28&gt;&#x27;, &#x27;&lt;extra_id_29&gt;&#x27;, &#x27;&lt;extra_id_30&gt;&#x27;, &#x27;&lt;extra_id_31&gt;&#x27;, &#x27;&lt;extra_id_32&gt;&#x27;, &#x27;&lt;extra_id_33&gt;&#x27;, &#x27;&lt;extra_id_34&gt;&#x27;, &#x27;&lt;extra_id_35&gt;&#x27;, &#x27;&lt;extra_id_36&gt;&#x27;, &#x27;&lt;extra_id_37&gt;&#x27;, &#x27;&lt;extra_id_38&gt;&#x27;, &#x27;&lt;extra_id_39&gt;&#x27;, &#x27;&lt;extra_id_40&gt;&#x27;, &#x27;&lt;extra_id_41&gt;&#x27;, &#x27;&lt;extra_id_42&gt;&#x27;, &#x27;&lt;extra_id_43&gt;&#x27;, &#x27;&lt;extra_id_44&gt;&#x27;, &#x27;&lt;extra_id_45&gt;&#x27;, &#x27;&lt;extra_id_46&gt;&#x27;, &#x27;&lt;extra_id_47&gt;&#x27;, &#x27;&lt;extra_id_48&gt;&#x27;, &#x27;&lt;extra_id_49&gt;&#x27;, &#x27;&lt;extra_id_50&gt;&#x27;, &#x27;&lt;extra_id_51&gt;&#x27;, &#x27;&lt;extra_id_52&gt;&#x27;, &#x27;&lt;extra_id_53&gt;&#x27;, &#x27;&lt;extra_id_54&gt;&#x27;, &#x27;&lt;extra_id_55&gt;&#x27;, &#x27;&lt;extra_id_56&gt;&#x27;, &#x27;&lt;extra_id_57&gt;&#x27;, &#x27;&lt;extra_id_58&gt;&#x27;, &#x27;&lt;extra_id_59&gt;&#x27;, &#x27;&lt;extra_id_60&gt;&#x27;, &#x27;&lt;extra_id_61&gt;&#x27;, &#x27;&lt;extra_id_62&gt;&#x27;, &#x27;&lt;extra_id_63&gt;&#x27;, &#x27;&lt;extra_id_64&gt;&#x27;, &#x27;&lt;extra_id_65&gt;&#x27;, &#x27;&lt;extra_id_66&gt;&#x27;, &#x27;&lt;extra_id_67&gt;&#x27;, &#x27;&lt;extra_id_68&gt;&#x27;, &#x27;&lt;extra_id_69&gt;&#x27;, &#x27;&lt;extra_id_70&gt;&#x27;, &#x27;&lt;extra_id_71&gt;&#x27;, &#x27;&lt;extra_id_72&gt;&#x27;, &#x27;&lt;extra_id_73&gt;&#x27;, &#x27;&lt;extra_id_74&gt;&#x27;, &#x27;&lt;extra_id_75&gt;&#x27;, &#x27;&lt;extra_id_76&gt;&#x27;, &#x27;&lt;extra_id_77&gt;&#x27;, &#x27;&lt;extra_id_78&gt;&#x27;, &#x27;&lt;extra_id_79&gt;&#x27;, &#x27;&lt;extra_id_80&gt;&#x27;, &#x27;&lt;extra_id_81&gt;&#x27;, &#x27;&lt;extra_id_82&gt;&#x27;, &#x27;&lt;extra_id_83&gt;&#x27;, &#x27;&lt;extra_id_84&gt;&#x27;, &#x27;&lt;extra_id_85&gt;&#x27;, &#x27;&lt;extra_id_86&gt;&#x27;, &#x27;&lt;extra_id_87&gt;&#x27;, &#x27;&lt;extra_id_88&gt;&#x27;, &#x27;&lt;extra_id_89&gt;&#x27;, &#x27;&lt;extra_id_90&gt;&#x27;, &#x27;&lt;extra_id_91&gt;&#x27;, &#x27;&lt;extra_id_92&gt;&#x27;, &#x27;&lt;extra_id_93&gt;&#x27;, &#x27;&lt;extra_id_94&gt;&#x27;, &#x27;&lt;extra_id_95&gt;&#x27;, &#x27;&lt;extra_id_96&gt;&#x27;, &#x27;&lt;extra_id_97&gt;&#x27;, &#x27;&lt;extra_id_98&gt;&#x27;, &#x27;&lt;extra_id_99&gt;&#x27;]}, clean_up_tokenization_spaces=True), use_caching=False)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FewShotClassifier</label><div class=\"sk-toggleable__content\"><pre>FewShotClassifier(generate_kwargs={&#x27;max_length&#x27;: 512}, model=T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=5...\n",
       "), tokenizer=T5TokenizerFast(name_or_path=&#x27;google/flan-t5-small&#x27;, vocab_size=32100, model_max_length=512, is_fast=True, padding_side=&#x27;right&#x27;, truncation_side=&#x27;right&#x27;, special_tokens={&#x27;eos_token&#x27;: &#x27;&lt;/s&gt;&#x27;, &#x27;unk_token&#x27;: &#x27;&lt;unk&gt;&#x27;, &#x27;pad_token&#x27;: &#x27;&lt;pad&gt;&#x27;, &#x27;additional_special_tokens&#x27;: [&#x27;&lt;extra_id_0&gt;&#x27;, &#x27;&lt;extra_id_1&gt;&#x27;, &#x27;&lt;extra_id_2&gt;&#x27;, &#x27;&lt;extra_id_3&gt;&#x27;, &#x27;&lt;extra_id_4&gt;&#x27;, &#x27;&lt;extra_id_5&gt;&#x27;, &#x27;&lt;extra_id_6&gt;&#x27;, &#x27;&lt;extra_id_7&gt;&#x27;, &#x27;&lt;extra_id_8&gt;&#x27;, &#x27;&lt;extra_id_9&gt;&#x27;, &#x27;&lt;extra_id_10&gt;&#x27;, &#x27;&lt;extra_id_11&gt;&#x27;, &#x27;&lt;extra_id_12&gt;&#x27;, &#x27;&lt;extra_id_13&gt;&#x27;, &#x27;&lt;extra_id_14&gt;&#x27;, &#x27;&lt;extra_id_15&gt;&#x27;, &#x27;&lt;extra_id_16&gt;&#x27;, &#x27;&lt;extra_id_17&gt;&#x27;, &#x27;&lt;extra_id_18&gt;&#x27;, &#x27;&lt;extra_id_19&gt;&#x27;, &#x27;&lt;extra_id_20&gt;&#x27;, &#x27;&lt;extra_id_21&gt;&#x27;, &#x27;&lt;extra_id_22&gt;&#x27;, &#x27;&lt;extra_id_23&gt;&#x27;, &#x27;&lt;extra_id_24&gt;&#x27;, &#x27;&lt;extra_id_25&gt;&#x27;, &#x27;&lt;extra_id_26&gt;&#x27;, &#x27;&lt;extra_id_27&gt;&#x27;, &#x27;&lt;extra_id_28&gt;&#x27;, &#x27;&lt;extra_id_29&gt;&#x27;, &#x27;&lt;extra_id_30&gt;&#x27;, &#x27;&lt;extra_id_31&gt;&#x27;, &#x27;&lt;extra_id_32&gt;&#x27;, &#x27;&lt;extra_id_33&gt;&#x27;, &#x27;&lt;extra_id_34&gt;&#x27;, &#x27;&lt;extra_id_35&gt;&#x27;, &#x27;&lt;extra_id_36&gt;&#x27;, &#x27;&lt;extra_id_37&gt;&#x27;, &#x27;&lt;extra_id_38&gt;&#x27;, &#x27;&lt;extra_id_39&gt;&#x27;, &#x27;&lt;extra_id_40&gt;&#x27;, &#x27;&lt;extra_id_41&gt;&#x27;, &#x27;&lt;extra_id_42&gt;&#x27;, &#x27;&lt;extra_id_43&gt;&#x27;, &#x27;&lt;extra_id_44&gt;&#x27;, &#x27;&lt;extra_id_45&gt;&#x27;, &#x27;&lt;extra_id_46&gt;&#x27;, &#x27;&lt;extra_id_47&gt;&#x27;, &#x27;&lt;extra_id_48&gt;&#x27;, &#x27;&lt;extra_id_49&gt;&#x27;, &#x27;&lt;extra_id_50&gt;&#x27;, &#x27;&lt;extra_id_51&gt;&#x27;, &#x27;&lt;extra_id_52&gt;&#x27;, &#x27;&lt;extra_id_53&gt;&#x27;, &#x27;&lt;extra_id_54&gt;&#x27;, &#x27;&lt;extra_id_55&gt;&#x27;, &#x27;&lt;extra_id_56&gt;&#x27;, &#x27;&lt;extra_id_57&gt;&#x27;, &#x27;&lt;extra_id_58&gt;&#x27;, &#x27;&lt;extra_id_59&gt;&#x27;, &#x27;&lt;extra_id_60&gt;&#x27;, &#x27;&lt;extra_id_61&gt;&#x27;, &#x27;&lt;extra_id_62&gt;&#x27;, &#x27;&lt;extra_id_63&gt;&#x27;, &#x27;&lt;extra_id_64&gt;&#x27;, &#x27;&lt;extra_id_65&gt;&#x27;, &#x27;&lt;extra_id_66&gt;&#x27;, &#x27;&lt;extra_id_67&gt;&#x27;, &#x27;&lt;extra_id_68&gt;&#x27;, &#x27;&lt;extra_id_69&gt;&#x27;, &#x27;&lt;extra_id_70&gt;&#x27;, &#x27;&lt;extra_id_71&gt;&#x27;, &#x27;&lt;extra_id_72&gt;&#x27;, &#x27;&lt;extra_id_73&gt;&#x27;, &#x27;&lt;extra_id_74&gt;&#x27;, &#x27;&lt;extra_id_75&gt;&#x27;, &#x27;&lt;extra_id_76&gt;&#x27;, &#x27;&lt;extra_id_77&gt;&#x27;, &#x27;&lt;extra_id_78&gt;&#x27;, &#x27;&lt;extra_id_79&gt;&#x27;, &#x27;&lt;extra_id_80&gt;&#x27;, &#x27;&lt;extra_id_81&gt;&#x27;, &#x27;&lt;extra_id_82&gt;&#x27;, &#x27;&lt;extra_id_83&gt;&#x27;, &#x27;&lt;extra_id_84&gt;&#x27;, &#x27;&lt;extra_id_85&gt;&#x27;, &#x27;&lt;extra_id_86&gt;&#x27;, &#x27;&lt;extra_id_87&gt;&#x27;, &#x27;&lt;extra_id_88&gt;&#x27;, &#x27;&lt;extra_id_89&gt;&#x27;, &#x27;&lt;extra_id_90&gt;&#x27;, &#x27;&lt;extra_id_91&gt;&#x27;, &#x27;&lt;extra_id_92&gt;&#x27;, &#x27;&lt;extra_id_93&gt;&#x27;, &#x27;&lt;extra_id_94&gt;&#x27;, &#x27;&lt;extra_id_95&gt;&#x27;, &#x27;&lt;extra_id_96&gt;&#x27;, &#x27;&lt;extra_id_97&gt;&#x27;, &#x27;&lt;extra_id_98&gt;&#x27;, &#x27;&lt;extra_id_99&gt;&#x27;]}, clean_up_tokenization_spaces=True), use_caching=False)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=FewShotClassifier(generate_kwargs={'max_length': 512}, model=T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=Fa...\n",
       "), tokenizer=T5TokenizerFast(name_or_path='google/flan-t5-small', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True), use_caching=False),\n",
       "             param_grid={'max_samples': [3, 5, 7]}, refit=False,\n",
       "             scoring=['accuracy', 'neg_log_loss'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time search.fit(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "851a10c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.227133</td>\n",
       "      <td>3</td>\n",
       "      <td>14.748633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.231064</td>\n",
       "      <td>5</td>\n",
       "      <td>37.663565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.91</td>\n",
       "      <td>-0.237118</td>\n",
       "      <td>7</td>\n",
       "      <td>33.848601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_accuracy  mean_test_neg_log_loss param_max_samples  \\\n",
       "0                0.92               -0.227133                 3   \n",
       "1                0.92               -0.231064                 5   \n",
       "2                0.91               -0.237118                 7   \n",
       "\n",
       "   mean_score_time  \n",
       "0        14.748633  \n",
       "1        37.663565  \n",
       "2        33.848601  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_)[['mean_test_accuracy', 'mean_test_neg_log_loss', 'param_max_samples', 'mean_score_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7501f6",
   "metadata": {},
   "source": [
    "**Conclusion**: No significant change in accuracy but medium improvement in log loss compared to zero shot. More than 5 samples don't seem to help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc6dd0",
   "metadata": {},
   "source": [
    "## Testing MNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3efcc",
   "metadata": {},
   "source": [
    "An existing method is to use natural language inference (NLI). Compare the results to https://huggingface.co/facebook/bart-large-mnli, which is the most used zero shot classifier on Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85cb43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd104d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('zero-shot-classification', model='facebook/bart-large-mnli', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ae22296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinh/anaconda3/envs/skorch/lib/python3.10/site-packages/transformers/pipelines/base.py:1080: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 7.61 ms, total: 13.7 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_probas = []\n",
    "for x in X:\n",
    "    output = classifier(x, ['negative', 'positive'])\n",
    "    if output['labels'] == ['negative', 'positive']:\n",
    "        y_probas.append(output['scores'])\n",
    "    else:\n",
    "        y_probas.append(output['scores'][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d914b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = np.vstack(y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9b51ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, y_proba.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "320b9c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3443705626436628"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627a511",
   "metadata": {},
   "source": [
    "**Conclusion**: This model is slower than the tested zero shot classifier, it is less flexible (we cannot adjust prompt or other parameters), and it performs worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff265941",
   "metadata": {},
   "source": [
    "## Testing vanilla ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2680514e",
   "metadata": {},
   "source": [
    "Use a standard TFIDF + logistic regression benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21334977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03019cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef862c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'tfidf__max_features': [500, 1000, 2000], 'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2), (1, 3)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b910ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(\n",
    "    tfidf, param_grid=params, cv=2, scoring=['accuracy', 'neg_log_loss'], refit=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9eea6075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 s, sys: 0 ns, total: 1.38 s\n",
      "Wall time: 1.38 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
       "             param_grid={&#x27;tfidf__max_features&#x27;: [500, 1000, 2000],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2), (2, 2),\n",
       "                                                (1, 3)]},\n",
       "             refit=False, scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                                       (&#x27;clf&#x27;, LogisticRegression())]),\n",
       "             param_grid={&#x27;tfidf__max_features&#x27;: [500, 1000, 2000],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2), (2, 2),\n",
       "                                                (1, 3)]},\n",
       "             refit=False, scoring=[&#x27;accuracy&#x27;, &#x27;neg_log_loss&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('clf', LogisticRegression())]),\n",
       "             param_grid={'tfidf__max_features': [500, 1000, 2000],\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2),\n",
       "                                                (1, 3)]},\n",
       "             refit=False, scoring=['accuracy', 'neg_log_loss'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615cd4bd",
   "metadata": {},
   "source": [
    "The table is quite big, let's look at the top 5 best log losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "150242f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_neg_log_loss</th>\n",
       "      <th>param_tfidf__max_features</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.662397</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.663959</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.664004</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.664215</td>\n",
       "      <td>1000</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.664609</td>\n",
       "      <td>500</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_accuracy  mean_test_neg_log_loss param_tfidf__max_features  \\\n",
       "3                0.69               -0.662397                       500   \n",
       "7                0.71               -0.663959                      1000   \n",
       "1                0.68               -0.664004                       500   \n",
       "5                0.70               -0.664215                      1000   \n",
       "0                0.65               -0.664609                       500   \n",
       "\n",
       "  param_tfidf__ngram_range  \n",
       "3                   (1, 3)  \n",
       "7                   (1, 3)  \n",
       "1                   (1, 2)  \n",
       "5                   (1, 2)  \n",
       "0                   (1, 1)  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['mean_test_accuracy', 'mean_test_neg_log_loss', 'param_tfidf__max_features', 'param_tfidf__ngram_range']\n",
    "pd.DataFrame(search.cv_results_)[cols].sort_values('mean_test_neg_log_loss', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f742bf",
   "metadata": {},
   "source": [
    "**Conclusion**: This classical model is much faster, even if we include the training time, because it is much smaller than an LLM. However, it's scores are also much worse, given the small dataset. If speed is no concern, using an LLM classifier would thus be a good option for this task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
